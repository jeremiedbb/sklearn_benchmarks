{"project": "scikit-learn", "project_url": "scikit-learn.org/", "show_commit_url": "https://github.com/scikit-learn/scikit-learn/commit/", "hash_length": 8, "revision_to_hash": {"382": "e6989efd71a2adddd03979d1fe7a2e82e37ea51f", "395": "8ff9fc895bd6032636e3716f02773fdcd9cdd3d3", "587": "0e1faafec9871df73e875a0aadfcb67ec578c0e5", "590": "a40d325cec40da6cbcff8193a4ab4890823dfc76", "646": "ddc6d8f80dcf0a6cdd606efdefb89211a4dc7e9d", "745": "8a4bc2f03733e530591d6641f266a60670a373f1", "755": "8216797c4b1abca9dafd8de9d65472d32450b389", "811": "c7208c1a43335179ccddafc7748c1d7224e904fc", "813": "47890ac823314f1a9e2920dff7575850af56c273", "826": "b573fc0dcbfc2528807b5f0f8c0bc719c25d36f4", "998": "65d06f830ec6604b44d1a0510255868a8f762e3a", "1016": "9072aa593d76262fe445cf492ffac77e853501ea", "1131": "959e267898090e3c68ee118d5048afad124ff61d", "1207": "c83447b72c4f48ceb8249ea394ebf042618b8a2a", "1288": "f13dba15e3d56455c58867685ec554755a346c32", "1915": "d6b4444bbcc54a241cc955a5ceea80be15e7db2b", "1917": "60589710bd64e1fb2ede4d34d7fbb57e83892c86", "1919": "eba9984f735478d47c956ede42bdefd28aa6f9f6", "1969": "0f148e0011fb873bcd70cb3cc01690e7d621f670", "1977": "dc72677a9c13a656cda8be4b23cd897b56109b4b", "2701": "2c3d9e2fce5d2bae27e10657aa3c7ff45c39b190", "2711": "87741a7c65768464eb15f0976ed4bf6312795e7f", "2743": "03a85c19ac2854f2a33f613f87e81fd5f4560f55", "3102": "c07f9574c902b68744434d7b43f7394e0801d64e", "3151": "8a195624128da773c7d584d9352f65d8241cc92d", "3212": "897201083fd584a310cb8a2870704470dc28474a", "3289": "bdf3332f9694f8ecbdcf7ab0391989e24ac13f88", "3741": "5a1e1f48433ba867fb035b9dc31882f8d90f7744", "3905": "af6ab92b3bc0286e401218631859ee50f8be23f7", "4037": "f7c9f24511d9b32add23e75bbf0a2a6c223d932f", "4054": "8b2aaf069306d6b61b49a29d32123e69991c153b", "4684": "cf5c72eb9dc7696b5fac61466605b2860942946e", "4696": "3b48abd5fb0fa4f87c09f6b21d0d1f0e8b7873e4", "6177": "3e3872cde115550b75bb25c47c109b8bfd070eab", "6225": "3f1ea662ee1b1b08cee63cc31e4e3e36ec532208", "6511": "bfd36aa504078ce58f727f7f37e17349ab290e7d", "7872": "4533aa33daa35dd68c6d433b1d3560ff2b65b252", "7904": "34334f5ce6b1f166efda8652310133f9fc36ed04", "7919": "79749fd2939781e201191ef081143d8a575984e7", "9331": "34c2904a95a707c6e6148480a7e2c86a0f7ad86b", "9349": "73fdf6a9c982758be6da71a932ec4a3613eccbbf", "9357": "4ae44b0fe10b3ddf8390cfa8deae4dec45c40666", "9369": "7eb39fa0dc43ce485d3af2857c587811332eb148", "9799": "114822b1e18c9d7f887c58b8a3b2c279bdce6d35", "10413": "4bc8822c846de0d3b70d006ea32235d4375a575b", "10436": "0fede44fb39d691e873d58a4210452aa93c462a5", "10457": "b9ed384195df7b8d7824eac42f7b1bee58ef321c", "10778": "0dd2e39c1f7aec6830e4348fa63a04939252a0a1", "12368": "3e89aa5f42519d7f0230b99948553a8eb33dc1f4", "12373": "86e8b0d2a3533253a7082591f572d73897c02a2c", "12748": "8075887585b0449b6e87ee54c2ca4dbd56960e1e", "14515": "fc0b766ceca487504b040896124a3d809af2975b", "14698": "d13928cc0653f52de55e22118915b0c5bcba13d7", "14725": "34c4908369968dd0f77897ec9dd8c227e7545478", "16940": "bc8666f60f2c8c9ba16b30fbe0b342c3b94213e6", "17074": "68280fb4254b0781a66a1d2689708068799f0bbe", "17075": "b4e8b3ca4366901998c116540902d2687e0a5450", "17279": "518002955b0d6539f8f5e2710b9cefb178cc8ee2", "17645": "d4906939b1ef86657e6617d8fa078a0fbe0c2472", "17934": "2068ff2fd94abe4f14b0334eb4372a64b268f6b4", "19198": "4cc0235ec1ee654ea85cf465d280d33bcb1db20c", "19199": "09dc09a1e9d9088c2cb783c818980f5509d77a11", "19375": "df9f90cfa8795b6d85056f70177fb783d6ecafda", "19504": "bb39b493ef084a4f362d77163c2ca506790c38b6", "19920": "25082e522c90fa9184789f6bc450278b3e18fdda", "20502": "c0c2c737971b52e04b1f6516dfa1bfb05b30f4fd", "20509": "cd12906cabf3576a8c236a4128e959360037dde0", "20952": "918005fd5441650ae4a49b510bcabff69ae898bf", "20955": "b5383488c4b8b97b000585e61ed4e2178fa84d36", "21113": "da4f480a6adf5fed30a42500fe0e5a21c404ac2a", "21126": "82fb053536803f172def9f64e0d62151529173a0", "21322": "2999a2f544cd56575d940d7ab359819b392cccae", "21323": "3c546fd1226a895f68d317d2430daa71fc13e093", "21601": "ea042f1485d5fe45bcf2475c3070cab4e5ac3381", "21602": "51a765acfa4c5d1ec05fc4b406968ad233c75162", "22266": "4d9fab55b9e14e01a7d13344a2612ed802d0c113", "22269": "b687ab371d990373c4a599399172cf31d2f0c350", "22284": "cef2b62701f80ff50a37528b5337dd9a96f0069e", "22395": "38030a00a7f72a3528bd17f2345f34d1344d6d45", "22704": "a5ab948cbc366d705b1f8db8687c7162f51de22d", "23212": "759f4637f9f9471cf4218b9dffc00b464790485b", "23295": "36bc053a69ac5b9ba5a54cb2bd19adb33dcde50e", "23298": "62523372fc6331fc55df73a94d65bfa48c45c193", "23322": "83816c2a95e2ae3c4b3546912de4f4266e0c230f", "23495": "81ba62fe053d56e228ce097cbca91bc5de2e3f82", "23783": "b661a9c81930429cba4a56af291ce2bf8c59f8c9", "24473": "8c439fbe8c340389d7f9d99884180b2e7b21a79f", "24725": "eb6764936c9558553f7a7203a6aaa0ddc6497875", "24890": "f659f5539f9d36ebec4e1d98538919b55299bba4", "25252": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1", "25365": "7389dbac82d362f296dc2746f10e43ffa1615660", "25508": "9ab4316fc9fed20563ad58b98c96807ec47b4d7e", "28315": "9b38bf4dea68bd01d9d398e9abb1f9b1a9127d9e"}, "revision_to_date": {"382": 1264603663000, "395": 1265024295000, "587": 1269007740000, "590": 1269244318000, "646": 1270698297000, "745": 1272878771000, "755": 1272909852000, "811": 1273294444000, "813": 1273337313000, "826": 1273550555000, "998": 1277561666000, "1016": 1277824675000, "1131": 1279558872000, "1207": 1280235748000, "1288": 1281104090000, "1915": 1286358759000, "1917": 1286371631000, "1919": 1286373337000, "1969": 1286782666000, "1977": 1286812002000, "2701": 1292596297000, "2711": 1292968871000, "2743": 1294669325000, "3102": 1298808434000, "3151": 1299078131000, "3212": 1299680572000, "3289": 1300670714000, "3741": 1302729559000, "3905": 1304345121000, "4037": 1305108339000, "4054": 1305126138000, "4684": 1309505367000, "4696": 1309545528000, "6177": 1316527045000, "6225": 1316642399000, "6511": 1318977607000, "7872": 1326216418000, "7904": 1326287141000, "7919": 1326426441000, "9331": 1336328405000, "9349": 1336407543000, "9357": 1336426836000, "9369": 1336524866000, "9799": 1341415689000, "10413": 1346780365000, "10436": 1346788092000, "10457": 1346981442000, "10778": 1349734773000, "12368": 1358801181000, "12373": 1358806382000, "12748": 1361636276000, "14515": 1375060310000, "14698": 1375915741000, "14725": 1375972053000, "16940": 1401972588000, "17074": 1404172403000, "17075": 1404240383000, "17279": 1405354512000, "17645": 1406899808000, "17934": 1409835738000, "19198": 1425667359000, "19199": 1425681522000, "19375": 1427396256000, "19504": 1429027572000, "19920": 1436588422000, "20502": 1445007457000, "20509": 1445013082000, "20952": 1445953225000, "20955": 1445958667000, "21113": 1446753465000, "21126": 1446818031000, "21322": 1450749753000, "21323": 1450761225000, "21601": 1455802186000, "21602": 1455802246000, "22266": 1473791605000, "22269": 1473799038000, "22284": 1473882154000, "22395": 1475007587000, "22704": 1478902517000, "23212": 1497903977000, "23295": 1499947923000, "23298": 1499952302000, "23322": 1500281648000, "23495": 1502470027000, "23783": 1505921382000, "24473": 1531668719000, "24725": 1535551327000, "24890": 1537887812000, "25252": 1542875805000, "25365": 1545209521000, "25508": 1548164832000, "28315": 1591489432000}, "params": {"arch": ["x86_64"], "cpu": ["Intel Core Processor (Haswell, no TSX)"], "machine": ["sklearn-benchmark"], "num_cpu": ["8"], "os": ["Linux 4.15.0-20-generic"], "ram": ["16424684"], "python": ["3.8"], "numpy": [""], "scipy": [""], "cython": [""], "joblib": [""], "branch": ["benchmark-bot"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "python": "3.8", "numpy": "", "scipy": "", "cython": "", "joblib": "", "branch": "benchmark-bot"}], "benchmarks": {"cluster.KMeansBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_fit", "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "setup_cache_key": "cluster:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "129f042b1b10ffd1a0357af6a098ea97819abee373b6c82a45303b3f1c0f2626"}, "cluster.KMeansBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_predict", "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "setup_cache_key": "cluster:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "55b3e984bed5b5cd7d255bfc3b86e5b13529d81ed80f2fb1403598dd1c44c2c3"}, "cluster.KMeansBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_transform", "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "setup_cache_key": "cluster:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "70314de5790c89dae6a4574794e18d2c3358162ee2b4c2684b87821d530721d9"}, "cluster.KMeansBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_fit", "number": 0, "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "8ef0af6dba49a222133a51c7a27dc34ad4d21829452582b66b69243ac3fc66e0", "warmup_time": 1}, "cluster.KMeansBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_predict", "number": 0, "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "800845a78db172e5e8d2e05ef109390735aad2b843f58381f51fa9a06b41e946", "warmup_time": 1}, "cluster.KMeansBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_transform", "number": 0, "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "087623a7f854681dc5f1ba62a17a47995e1835697041a5f59cb3f87878220d56", "warmup_time": 1}, "cluster.KMeansBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_test_score", "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "setup_cache_key": "cluster:20", "timeout": 500, "type": "track", "unit": "unit", "version": "571019295fd42a7aaa7b98df2480aa15ea01a3e225db706a191eb1768fae83f4"}, "cluster.KMeansBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_train_score", "param_names": ["representation", "algorithm"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"]], "setup_cache_key": "cluster:20", "timeout": 500, "type": "track", "unit": "unit", "version": "fc06b618d8be829abbe1e102f257f9cf76cfe2ece8cdb769fbed7662b18935f8"}, "cluster.KMeansPlusPlusBenchmark.peakmem_kmeansplusplus": {"code": "class KMeansPlusPlusBenchmark:\n    def peakmem_kmeansplusplus(self, *args):\n        _k_init(self.X, self.n_clusters, self.x_squared_norms,\n                random_state=np.random.RandomState(0))\n\n    def setup(self, *params):\n        representation, = params\n    \n        if representation == 'sparse':\n            data = _20newsgroups_highdim_dataset(ngrams=(1, 2))\n            self.n_clusters = 20\n        else:\n            data = _blobs_dataset()\n            self.n_clusters = 256\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.x_squared_norms = row_norms(self.X, squared=True)", "name": "cluster.KMeansPlusPlusBenchmark.peakmem_kmeansplusplus", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e01af47f997159b975268b5aa33216ce15fb6d5abcba1b5166e44da0fde4f7f5"}, "cluster.KMeansPlusPlusBenchmark.time_kmeansplusplus": {"code": "class KMeansPlusPlusBenchmark:\n    def time_kmeansplusplus(self, *args):\n        _k_init(self.X, self.n_clusters, self.x_squared_norms,\n                random_state=np.random.RandomState(0))\n\n    def setup(self, *params):\n        representation, = params\n    \n        if representation == 'sparse':\n            data = _20newsgroups_highdim_dataset(ngrams=(1, 2))\n            self.n_clusters = 20\n        else:\n            data = _blobs_dataset()\n            self.n_clusters = 256\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.x_squared_norms = row_norms(self.X, squared=True)", "min_run_count": 2, "name": "cluster.KMeansPlusPlusBenchmark.time_kmeansplusplus", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "timeout": 500, "type": "time", "unit": "seconds", "version": "3f3d7788d3b25a4a2e5259e666a8cd44837b56fbfff437423a2e548800ebac78", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:43", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "1e99e55aa95fd06679e92190871a3cc6bd7c7cb1f935fa46756cfecdbb2d092b"}, "decomposition.DictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:43", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "0c71bcec781716917f135610e3871334615618085b06d7500c721e18e8f63c63"}, "decomposition.DictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:43", "timeout": 500, "type": "time", "unit": "seconds", "version": "f8c0911224a4e44563c23c44d4f1df95068340e41b57f04f4955a5f5ab029e80", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:43", "timeout": 500, "type": "time", "unit": "seconds", "version": "f08d61c4f12548595cc019612a37faaa8f1341c4676722062b1274c4b4588b0c", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:43", "timeout": 500, "type": "track", "unit": "unit", "version": "02366e653098082f6bfb65793d19179c91cb596b1798e4884cef6a69434751d9"}, "decomposition.DictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:43", "timeout": 500, "type": "track", "unit": "unit", "version": "c06e24b3c2306910464c9ae3e3fe6cca3ebfb91234cf21253c88bedf5692d049"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:73", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e8c19f4be5973512b58b6d03bc42a762a1012ca585f21cf6ec403114f4308916"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:73", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "771ad57dba166d2a7e21ec1c0fa68330280450a27d560bf05094e370452e0bc8"}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:73", "timeout": 500, "type": "time", "unit": "seconds", "version": "6675364a14322439e00cd94d8dbe8e5e0324f832a9905b4fb38455657ad31d41", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:73", "timeout": 500, "type": "time", "unit": "seconds", "version": "460b5be478c073d13a9d16c9e33d2d4a07094aed46df4f9f705cf9ebd87281ff", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:73", "timeout": 500, "type": "track", "unit": "unit", "version": "bfe92c4d752230e6395d9d62848a93202ff986a30de165b9c506a684cdfed202"}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1"]], "setup_cache_key": "decomposition:73", "timeout": 500, "type": "track", "unit": "unit", "version": "ec3e5a11f36b9ebd4df4fab59e589179b2a6ac7d89b452b7934632d752a56231"}, "decomposition.PCABenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_fit", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e39eace13b691bcbae93ba4a7fd9e6dba443c3d5e484e2a36ce18ccd0a261064"}, "decomposition.PCABenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_transform", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "5a991be7ce589a23fda348c01ed73adbd99724510e7a3d7ee00b3a6c89483573"}, "decomposition.PCABenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_fit", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "64ebff1b913655ed2040107a09c6cc46e6866ec4a2e82a3351f2c723a57ceddc", "warmup_time": 1}, "decomposition.PCABenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_transform", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "33e74dcc420628f68e1d097c4ea9a09bbd46668eb4ca5953a202d370dafa3e05", "warmup_time": 1}, "decomposition.PCABenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_test_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "track", "unit": "unit", "version": "3977aaa369574a6fe0ed8dee39b35128f6d10e61f5757892d479244e8d421dbe"}, "decomposition.PCABenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_train_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "track", "unit": "unit", "version": "b18cfbd01e2498366d2773375645a86eba63f2282e8ce49f94450c4ffe927676"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:50", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "54524d256fed3ef795e22f92a616fc7cb5cad61f89e5fa87e5bbc76714b876ab"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:50", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "12c313f6ef721218bdf66d2cbb9abca9067e0fe7a456928679fecbce5176c6de"}, "ensemble.GradientBoostingClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:50", "timeout": 500, "type": "time", "unit": "seconds", "version": "e3cd2fb4a1b838384f8d52a28cd0fc8a854c04850b29c5e1202e3b262c2fc486", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:50", "timeout": 500, "type": "time", "unit": "seconds", "version": "4660de9436777bf07a9d529bad637e20e93cb111bde96775a1708c984e438776", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:50", "timeout": 500, "type": "track", "unit": "unit", "version": "13bcc83128cd9b5b6dea61b5cdfb59c50408e2abbcddde64219e97f0863e6242"}, "ensemble.GradientBoostingClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:50", "timeout": 500, "type": "track", "unit": "unit", "version": "81638708e401891f8724642232b6b74a765030163aed043ec15041738eff4ea9"}, "ensemble.RandomForestClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_fit", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "setup_cache_key": "ensemble:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "8f500d8fb4bcc174497617f88dca99a6276d25119311968d068896e58f548873"}, "ensemble.RandomForestClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_predict", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "setup_cache_key": "ensemble:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "2c8fcb52c5f7bea3435ba13f4e5c1fa1b1a7a7ad0214b0461ae596a9c9ca5594"}, "ensemble.RandomForestClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "294ec82e5cb66f1b3bbc3e17a4ccff982dfd1e1673013e5f37105a8b34bb7858", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "6dc2637a26579005f4b8160a7f64729ccb752503b99af42edf5c34ffe2056ea3", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_test_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "setup_cache_key": "ensemble:17", "timeout": 500, "type": "track", "unit": "unit", "version": "a417e681d4946e6c1f037a80d41340ab200ea7da88ec1b9fe86d90c6b6e570cc"}, "ensemble.RandomForestClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_train_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1"]], "setup_cache_key": "ensemble:17", "timeout": 500, "type": "track", "unit": "unit", "version": "6c2bfe2c3be361036f3dd3da35952daa531ab57a16c34cd2d8aa9abe4fb7453d"}, "linear_model.ElasticNetBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:161", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "67dbc0768f897a9088e276ab637afe2b2e32db9e57674429b0d6d7c942e9bd05"}, "linear_model.ElasticNetBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:161", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e689ffb8ac911a2dabfbefbd215b125bee3bb3efa1aef84781a139eb2d9c0a29"}, "linear_model.ElasticNetBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:161", "timeout": 500, "type": "time", "unit": "seconds", "version": "58145c85bdb148b6dcdbaccee384ea0b1d6d49a3a16808e828313312d555fa5b", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:161", "timeout": 500, "type": "time", "unit": "seconds", "version": "26373422331b4f7f5cbee6b902dcc56b060fb68717db8e8094b767681074f19f", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:161", "timeout": 500, "type": "track", "unit": "unit", "version": "7d389c3c48b3ac852156c5dcf3417a95f392895a948f51ede68f9bc704e6d123"}, "linear_model.ElasticNetBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:161", "timeout": 500, "type": "track", "unit": "unit", "version": "65dd82e0754b7ae64fad3f022f58e6e4b769411f25c15a24f5212884e7fff3e5"}, "linear_model.LassoBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:201", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "06073d90ad257eeef94f50565cecf19ff1d0759f6698ebc06ae5d571983fad4f"}, "linear_model.LassoBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:201", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "a90e1fcd326d594c99c6727e5e1d6ea2b6e2664aa6f5da240395cda651187a7e"}, "linear_model.LassoBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:201", "timeout": 500, "type": "time", "unit": "seconds", "version": "37d94ba51df53c1b2991fe5779bd1fd6b2ac5bfb4e10f2fb8de236be227a69e0", "warmup_time": 1}, "linear_model.LassoBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:201", "timeout": 500, "type": "time", "unit": "seconds", "version": "f8b3b4d3cee30af00c896ee907296b56e66936a9fa26f72b88eeff1395ee3144", "warmup_time": 1}, "linear_model.LassoBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:201", "timeout": 500, "type": "track", "unit": "unit", "version": "b5b4d3816e3277e476a1fca01ec892c348610d7f97c5665237d371e5f3332cb7"}, "linear_model.LassoBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:201", "timeout": 500, "type": "track", "unit": "unit", "version": "19a5a52df653e4820c643ba9e48ac97515f8d9043d6e16b9df78cf4d3cccee53"}, "linear_model.LinearRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:101", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "11a090b8ec574f7c4b19b7aac9f44e6f048a15d13e407e797177175d5ba3a2ee"}, "linear_model.LinearRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:101", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "66443763d181de6ddf3571486c5c245c44ae001398c9d37ca2886fda8f001b8e"}, "linear_model.LinearRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:101", "timeout": 500, "type": "time", "unit": "seconds", "version": "57d6b8dc88c84da7166d894ebd405be8707faf9d22dbfb04d24d59e50cbffb7f", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:101", "timeout": 500, "type": "time", "unit": "seconds", "version": "4b376c64055c2bb598c500c530d6f3d9fee2d9b64be9eb0959ffe99daeff3746", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:101", "timeout": 500, "type": "track", "unit": "unit", "version": "0b08ef6224e1dbec49f38b0b6c1208856744fd3a7970714e6c1873d59345c82d"}, "linear_model.LinearRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:101", "timeout": 500, "type": "track", "unit": "unit", "version": "c9007f859c978a6c9a49f4c92a05a535f5f9296ca13c4047a75ef0405ace4f8c"}, "linear_model.LogisticRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_fit", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "bf5038e7f52c210188ab25f321dc8a998cf6b7251143de9ca5e6cfb43a02a3ed"}, "linear_model.LogisticRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_predict", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "71fad4c80b0dbb6bf90b8a4860d35c3fed5a4e763aa0ae20aeda2ad927f3af39"}, "linear_model.LogisticRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "fd40d8d1b477ea748edc6cd9d8fd1386965f99f56cbdd8c20caf0257b41d14da", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "0260c1e21c7ff2501269d1da194331a84613d7a5dc9980622e33284300cc56e7", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_test_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "track", "unit": "unit", "version": "b4bd200a241dccc3aaf741f0934311df0ad0c637d7f9892675eac3a2d55a65e9"}, "linear_model.LogisticRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_train_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "track", "unit": "unit", "version": "6cd50e0afdff6281f3765bcee8af4b58ff8b6dbd7a6f723568afb2019faea29e"}, "linear_model.RidgeBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_fit", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:61", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "301acadcd47db1be1482f8e0a512b8e5377da46f246aeefc89b192c93d503933"}, "linear_model.RidgeBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_predict", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:61", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "0bdf3ca68fc0ed24ddced2c98ca5a9a931bccf28db9ee880e9eb2401ab5dc361"}, "linear_model.RidgeBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:61", "timeout": 500, "type": "time", "unit": "seconds", "version": "bfdb41bc0b2fa1a0144d10b0cf1a2e440a0fd8dc577ac4c0733ad7856499cf0a", "warmup_time": 1}, "linear_model.RidgeBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:61", "timeout": 500, "type": "time", "unit": "seconds", "version": "3da574ebdebc93cfbd9a2ba25c7b3a0a1aca043d89f61bc92862a39304ef4791", "warmup_time": 1}, "linear_model.RidgeBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_test_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:61", "timeout": 500, "type": "track", "unit": "unit", "version": "cf549ea32dff9b4bc95e9d3aa0b09be2b7704056904f58214be39512b1966ef2"}, "linear_model.RidgeBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_train_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:61", "timeout": 500, "type": "track", "unit": "unit", "version": "3bd8dbb9b0d76425fd301bbd7f64a0052f9b7af283a85c47b644d32d9c894131"}, "linear_model.SGDRegressorBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:130", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "42ebc445481e7c478d02f409a8c50c6dba806c1ec2eabd5f1caf5e3067993fc9"}, "linear_model.SGDRegressorBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:130", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "7afedb7319cc6f9ecd1962c6534db5481f2afdc5f21a232c42f9332e02d0fb42"}, "linear_model.SGDRegressorBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:130", "timeout": 500, "type": "time", "unit": "seconds", "version": "84566455065371342317b542c652b9e73402de143bdfa430c813cde7c51132a0", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:130", "timeout": 500, "type": "time", "unit": "seconds", "version": "342a63ee3c7792b52f8c9f17b39ba39e9cd13d04439d11db35f9ebab979a4062", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:130", "timeout": 500, "type": "track", "unit": "unit", "version": "c61ed375318f86a23b326a57524f4d669c55ad7e65a38240c7e2a9cd15ff2a61"}, "linear_model.SGDRegressorBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:130", "timeout": 500, "type": "track", "unit": "unit", "version": "584debfad932e02195fbc9d09bdd5d7f9b11107f2ec492696e6aa6bfbfc55575"}, "manifold.TSNEBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.peakmem_fit", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "c7d5dfb9320c3915ab847f42548181b722d0afbc0f3f9c5d511550c9544ee356"}, "manifold.TSNEBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "manifold.TSNEBenchmark.time_fit", "number": 0, "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "manifold:15", "timeout": 500, "type": "time", "unit": "seconds", "version": "fc30c13a6cdf08613c8fe525485eeb7e64e1625fe0dcdd13923349fc9bafc112", "warmup_time": 1}, "manifold.TSNEBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_test_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "7fda5d07bef789bae809c29d39bfc605ccc21dd64aaeeb88a2410e5d5c84c0dd"}, "manifold.TSNEBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_train_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "b21f314a4f045aa489c3adc98970e040d7df520e1ca94bb47220c7b55fc1a36d"}, "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def peakmem_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == 'sparse' and metric == 'correlation':\n            raise NotImplementedError\n    \n        if Benchmark.data_size == 'large':\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples,\n                               representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {'metric': metric,\n                             'n_jobs': n_jobs}", "name": "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances", "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1"]], "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "9e233ad5c2450fe03927e9610c457ce1c967b83279fe878e2280101e3e1ae80d"}, "metrics.PairwiseDistancesBenchmark.time_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def time_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == 'sparse' and metric == 'correlation':\n            raise NotImplementedError\n    \n        if Benchmark.data_size == 'large':\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples,\n                               representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {'metric': metric,\n                             'n_jobs': n_jobs}", "min_run_count": 2, "name": "metrics.PairwiseDistancesBenchmark.time_pairwise_distances", "number": 0, "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1"]], "rounds": 1, "sample_time": 0.01, "timeout": 500, "type": "time", "unit": "seconds", "version": "9fed496f3dad2c9dc76f028f417784b342266ee16197672e899e403a5447b57c", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.peakmem_crossval": {"code": "class CrossValidationBenchmark:\n    def peakmem_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "name": "model_selection.CrossValidationBenchmark.peakmem_crossval", "param_names": ["n_jobs"], "params": [["1"]], "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "6801caf1f8cd21ed17a0095ee8a6a4f32e18fc9c4fda5efc812cd8c88053146b"}, "model_selection.CrossValidationBenchmark.time_crossval": {"code": "class CrossValidationBenchmark:\n    def time_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "min_run_count": 2, "name": "model_selection.CrossValidationBenchmark.time_crossval", "number": 0, "param_names": ["n_jobs"], "params": [["1"]], "rounds": 1, "sample_time": 0.01, "timeout": 20000, "type": "time", "unit": "seconds", "version": "be3520243b65d79e9c474fd2297b14127cf9de93ebc3c36d5cbf473e515a7f51", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.track_crossval": {"code": "class CrossValidationBenchmark:\n    def track_crossval(self, *args):\n        return float(cross_val_score(self.clf, self.X,\n                                     self.y, **self.cv_params).mean())\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "name": "model_selection.CrossValidationBenchmark.track_crossval", "param_names": ["n_jobs"], "params": [["1"]], "timeout": 20000, "type": "track", "unit": "unit", "version": "74d326542acd7965a4ac38cd7dcbf848a4ee175d5aee479001a1e7846287e113"}, "model_selection.GridSearchBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_fit", "param_names": ["n_jobs"], "params": [["1"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "42c51ebbb0826b723a90a8df3756f4d4bdd46a1953bd9f1889bbe41c4d505ae0"}, "model_selection.GridSearchBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_predict", "param_names": ["n_jobs"], "params": [["1"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "7f71976ee9791fb0d60c9c7df7664b993e1b9eb81ee699e97c20ffe25cd44660"}, "model_selection.GridSearchBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_fit", "number": 0, "param_names": ["n_jobs"], "params": [["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "time", "unit": "seconds", "version": "720c6ded45fd41f20c93be5b830b2ff0555afc9c354e169f8551b8b462351480", "warmup_time": 1}, "model_selection.GridSearchBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_predict", "number": 0, "param_names": ["n_jobs"], "params": [["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "time", "unit": "seconds", "version": "0718097b79e8d198c9171d5054e3c093fd12f4d8202ba3b7cb9bbaccc3277958", "warmup_time": 1}, "model_selection.GridSearchBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_test_score", "param_names": ["n_jobs"], "params": [["1"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "track", "unit": "unit", "version": "cf673ab7c8cc7134ecf5608e42489ce4a9cfab112197335ee0977eea30616c31"}, "model_selection.GridSearchBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_train_score", "param_names": ["n_jobs"], "params": [["1"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "track", "unit": "unit", "version": "a9a27a79ad4862771a0a1b3f3e8cd9d4940151335eb52c9541d01ef30865de89"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_fit", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "20a5835d388fda80a6b91ed4968b5525f2f565de9c14161fc1621a0b2589db52"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_predict", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "4a6f38a50a57383b573ab21431444dface79f795031777badd3c8727843e2803"}, "neighbors.KNeighborsClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_fit", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:18", "timeout": 500, "type": "time", "unit": "seconds", "version": "6c8595433fc00c666bdd19ffc40407287ece635162d3c8fb0d5163ddc0230795", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_predict", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:18", "timeout": 500, "type": "time", "unit": "seconds", "version": "c68d6f874cd8004cdd32cdf5ad661ca028463c67b44dddfa259ec08b31381a21", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_test_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "track", "unit": "unit", "version": "39dc1b35bfb1d0d7490eca69a4f48973c294ee86c285c3153c8630f5ad836e16"}, "neighbors.KNeighborsClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_train_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "track", "unit": "unit", "version": "3ca5f30d8fac92ef285c6418a6ded6957877c34db2df881188ac41d87af5b879"}, "svm.SVCBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_fit", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "09fe347a09177f41d67c0aa01462b935fe3a00487e13b3309aee97da34301e4a"}, "svm.SVCBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_predict", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "ab1fa7abb727a32d97120d69b8f26119d32549a827ee535f0199f69b9f42f7df"}, "svm.SVCBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_fit", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "fe0ae11d5daf692ab7b0d5cc75bfae69487f86d8d8f52842f22148cde6a8d7dc", "warmup_time": 1}, "svm.SVCBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_predict", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "16ca4065c69a0dc0eddf9f6068af61f5bfd244faa3a177054de53a0a68dbab0b", "warmup_time": 1}, "svm.SVCBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_test_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "ee86cd70cbcc77a00ff78f8150c73121cf1c85a675a7f27b3f19c1c8a9f7e490"}, "svm.SVCBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Run for each param combination\n    \n        Load the pickled dataset and fitted estimator and run the benchmark.\n        \"\"\"\n        if hasattr(self, 'setup_'):\n            self.setup_(params)\n    \n        data_path = get_data_path(self, params)\n        with open(data_path, 'rb') as f:\n            self.X, self.X_val, self.y, self.y_val = pickle.load(f)\n    \n        est_path = get_estimator_path(self, Benchmark.save_folder,\n                                      params, Benchmark.save_estimators)\n        with open(est_path, 'rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_train_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "f0b8f074b09b1a3e3144bad8944eb5b8cfa36195d4ea6fa50e082c15947b5eca"}}, "machines": {"sklearn-benchmark": {"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "version": 1}}, "tags": {"0.1": 395, "0.1-beta": 382, "0.10": 7904, "0.10-branching": 7872, "0.11": 9357, "0.11-beta": 9331, "0.11-branching": 9349, "0.12": 10436, "0.12-branching": 10413, "0.12.1": 10778, "0.13": 12373, "0.13-branching": 12368, "0.13.1": 12748, "0.14": 14698, "0.14.1": 14725, "0.14a1": 14515, "0.15-branching": 17074, "0.15.0": 17279, "0.15.0b1": 16940, "0.15.0b2": 17075, "0.15.1": 17645, "0.15.2": 17934, "0.16-branching": 19198, "0.16.0": 19375, "0.16.1": 19504, "0.16b1": 19199, "0.17": 21113, "0.17-branching": 20502, "0.17.1": 21601, "0.17.1-1": 21602, "0.17b1": 20509, "0.18": 22395, "0.18.1": 22704, "0.18.2": 23212, "0.18rc": 22266, "0.18rc1": 22269, "0.18rc2": 22284, "0.19-branching": 23295, "0.19.0": 23495, "0.19.1": 23783, "0.19.2": 24473, "0.19b1": 23298, "0.19b2": 23322, "0.2": 590, "0.2-beta": 587, "0.20.0": 24890, "0.20.1": 25252, "0.20.2": 25365, "0.20rc1": 24725, "0.3": 745, "0.4": 998, "0.5": 1969, "0.5.rc": 1915, "0.5.rc2": 1917, "0.5.rc3": 1919, "0.6-rc": 2701, "0.6.0": 2711, "0.7": 3151, "0.7-branching": 3102, "0.7.1": 3212, "0.8": 4037, "0.8-branching": 3905, "0.8.1": 4684, "0.9": 6225, "0.9-branching": 6177, "archive/kmeans-wheels": 25508, "debian/0.10.0-1": 7919, "debian/0.11.0-1": 9369, "debian/0.11.0-2": 9799, "debian/0.12.0-1": 10457, "debian/0.16.1-2": 19920, "debian/0.17.0-1": 21126, "debian/0.17.0-3": 21322, "debian/0.17.0-4": 21323, "debian/0.17.0_b1+git14-g4e6829c-1": 20955, "debian/0.17.0_b1-1": 20952, "debian/0.2+svn625-1": 646, "debian/0.3-1": 755, "debian/0.3-2": 811, "debian/0.3-3": 813, "debian/0.3-4": 826, "debian/0.4-1": 1016, "debian/0.4-2": 1131, "debian/0.4-3": 1288, "debian/0.5-1": 1977, "debian/0.6.0.dfsg-1": 2743, "debian/0.7.1.dfsg-1": 3289, "debian/0.7.1.dfsg-3": 3741, "debian/0.8.0.dfsg-1": 4054, "debian/0.8.1.dfsg-1": 4696, "debian/0.9.0.dfsg-1": 6511, "sprint01": 1207}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}